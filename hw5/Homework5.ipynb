{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Derek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import d2l\n",
    "import mxnet as mx\n",
    "from mxnet import autograd, gluon, init, nd\n",
    "from mxnet.gluon import data as gdata, loss as gloss, nn, utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mnist_train = gdata.vision.FashionMNIST(train=True)\n",
    "mnist_test = gdata.vision.FashionMNIST(train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(o, y):\n",
    "    loss = gluon.loss.LogisticLoss()\n",
    "    return loss(o, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(forward_func, o):\n",
    "    o.attach_grad()\n",
    "    with autograd.record():\n",
    "        z = forward_func(o, nd.array([1]))\n",
    "    z.backward()\n",
    "    return o.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = nd.arange(-5, 5, step=0.11)\n",
    "oneDerivs = nd.zeros(zeros.shape)\n",
    "for i in range(len(zeros)):\n",
    "    oneDerivs[i] = grad(loss, zeros[i]).asscalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(zeros.asnumpy(), oneDerivs.asnumpy())\n",
    "plt.xlabel('Values of o')\n",
    "plt.ylabel('Derivatives')\n",
    "plt.title('o vs. Derivatives for y = 1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shirt_sweater = []\n",
    "sandal_sneaker = []\n",
    "#shirt: 6, sweater: 2, sandal: 5, sneaker: 7\n",
    "for i in range(len(mnist_train._label)):\n",
    "    label = mnist_train._label[i]\n",
    "    if label == 6 or label == 2:\n",
    "        shirt_sweater.append(i)\n",
    "    elif label == 5 or label == 7:\n",
    "        sandal_sneaker.append(i)\n",
    "\n",
    "class_1_train = mnist_train[shirt_sweater][0]\n",
    "class_neg1_train = mnist_train[sandal_sneaker][0]\n",
    "\n",
    "class_1_train = class_1_train.reshape(12000, 784)\n",
    "class_neg1_train = class_neg1_train.reshape(12000, 784)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_1_test_data = []\n",
    "class_neg1_test_data = []\n",
    "#shirt: 6, sweater: 2, sandal: 5, sneaker: 7\n",
    "for i in range(len(mnist_test._label)):\n",
    "    label = mnist_test._label[i]\n",
    "    if label == 6 or label == 2:\n",
    "        class_1_test_data.append(i)\n",
    "    elif label == 5 or label == 7:\n",
    "        class_neg1_test_data.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0  0  0 ...  0  0  0]\n",
       " [ 0  0  0 ... 56  0  0]\n",
       " [ 0  0  0 ...  0  0  0]\n",
       " ...\n",
       " [ 0  0  0 ... 34  0  0]\n",
       " [ 0  0  0 ...  0  0  0]\n",
       " [ 0  0  0 ...  0  0  0]]\n",
       "<NDArray 2000x784 @cpu(0)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_1_test = mnist_test[class_1_test_data][0]\n",
    "class_neg1_test = mnist_test[class_neg1_test_data][0]\n",
    "\n",
    "class_1_test = class_1_test.reshape(2000, 784)\n",
    "class_neg1_test = class_neg1_test.reshape(2000, 784)\n",
    "class_1_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24000, 784) (24000,)\n"
     ]
    }
   ],
   "source": [
    "train_data = nd.concat(class_1_train, class_neg1_train, dim = 0)\n",
    "train_data = train_data.astype('float32')\n",
    "train_labels = nd.concat(nd.ones(len(class_1_train)), nd.ones(len(class_neg1_train))*-1, dim = 0)\n",
    "train_labels = train_labels.astype('float32')\n",
    "print(train_data.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 784) (4000,)\n"
     ]
    }
   ],
   "source": [
    "test_data = nd.concat(class_1_test, class_neg1_test, dim = 0)\n",
    "test_data = test_data.astype('float32')\n",
    "test_labels = nd.concat(nd.ones(len(class_1_test_data)), nd.ones(len(class_neg1_test_data))*-1, dim = 0)\n",
    "print(test_data.shape, test_labels.shape)\n",
    "\n",
    "def makeTrainData(class1, class0, size, l):\n",
    "    class1 = class1[:l*size]\n",
    "    class0 = class0[:(1-l)*size]\n",
    "    train_data = nd.concat(class1, class0, dim = 0)\n",
    "    train_data = train_data.astype('float32')\n",
    "    train_labels = nd.concat(nd.ones(len(class1)), nd.ones(len(class0))*-1, dim = 0)\n",
    "    train_labels = train_labels.astype('float32')\n",
    "    return (train_data, train_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeTrainData(class1, class0, size, l):\n",
    "    class1 = class1[:int(l*size)]\n",
    "    class0 = class0[:int((1-l)*size)]\n",
    "\n",
    "    train_data = nd.concat(class1, class0, dim = 0)\n",
    "    train_data = train_data.astype('float32')\n",
    "    train_labels = nd.concat(nd.ones(len(class1)), nd.ones(len(class0))*-1, dim = 0)\n",
    "    train_labels = train_labels.astype('float32')\n",
    "    return (train_data, train_labels)\n",
    "\n",
    "train_data, train_labels = makeTrainData(class_1_train, class_neg1_train, 12000, .5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(z):\n",
    "    return 1. / (1. + nd.exp(-z))\n",
    "\n",
    "def train_and_predict(Xtrain, ytrain, Xtest, ytest):\n",
    "    batch_size = 64\n",
    "    num_epochs = 20\n",
    "    \n",
    "    train_dataset = gdata.ArrayDataset(Xtrain, ytrain)\n",
    "    train_iter = gdata.DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "\n",
    "    def loss(o, y):\n",
    "        loss = gluon.loss.LogisticLoss()\n",
    "        return loss(o, y)\n",
    "\n",
    "    def net():\n",
    "        net = nn.Sequential()\n",
    "        net.add(nn.Dense(1))\n",
    "        net.initialize(init.Normal(sigma=1))\n",
    "        return net\n",
    "\n",
    "    net = net()\n",
    "    trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.1})\n",
    "    for epoch in range(num_epochs):\n",
    "        for X, y in train_iter:\n",
    "            with autograd.record():\n",
    "                l = loss(net(X), y)\n",
    "            l.backward()\n",
    "            trainer.step(batch_size)\n",
    "        l = loss(net(Xtrain), ytrain)\n",
    "        #print('epoch %d, loss: %f' % (epoch, l.mean().asnumpy()))\n",
    "    \n",
    "    pred_labels = net(Xtest)\n",
    "    predictions = []\n",
    "    for i in pred_labels:\n",
    "        if i.asscalar() > 0:\n",
    "            predictions.append(1)\n",
    "        else:\n",
    "            predictions.append(-1)\n",
    "    predictions = np.asarray(predictions)\n",
    "    actual = ytest.astype(\"int\").asnumpy()\n",
    "\n",
    "    return np.count_nonzero(predictions == actual)/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9995"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full test set\n",
    "train_data, train_labels = makeTrainData(class_1_train, class_neg1_train, 24000, .5)\n",
    "\n",
    "train_and_predict(train_data, train_labels, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99875"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# half test set\n",
    "train_data, train_labels = makeTrainData(class_1_train, class_neg1_train, 12000, .5)\n",
    "\n",
    "train_and_predict(train_data, train_labels, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = [.05, .1, .2, .3, .4, .5, .6, .7, .8, .9, .95]\n",
    "\n",
    "datasets = list(map(lambda x: makeTrainData(class_1_train, class_neg1_train, 12000, x), lambdas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 accuracy: 0.99575\n",
      "0.1 accuracy: 0.99875\n",
      "0.2 accuracy: 0.999\n",
      "0.3 accuracy: 0.99875\n",
      "0.4 accuracy: 0.99875\n",
      "0.5 accuracy: 0.999\n",
      "0.6 accuracy: 0.999\n",
      "0.7 accuracy: 0.99875\n",
      "0.8 accuracy: 0.99825\n",
      "0.9 accuracy: 0.996\n",
      "0.95 accuracy: 0.9935\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for train_data, train_labels in datasets:\n",
    "    print(str(lambdas[i]) + \" accuracy: \" + str(train_and_predict(train_data, train_labels, test_data, test_labels)))\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1. We want to reweight all of our training data by exp(min(f(xi), c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ 1.  1.  1. ... -1. -1. -1.]\n",
      "<NDArray 16000 @cpu(0)>\n",
      "epoch 0, loss: 3963.504395\n",
      "epoch 1, loss: 3580.795898\n",
      "epoch 2, loss: 913.939026\n",
      "epoch 3, loss: 1298.052734\n",
      "epoch 4, loss: 5932.034180\n",
      "epoch 5, loss: 1004.988037\n",
      "epoch 6, loss: 6137.037109\n",
      "epoch 7, loss: 2826.469971\n",
      "epoch 8, loss: 10062.743164\n",
      "epoch 9, loss: 6568.000000\n",
      "epoch 10, loss: 1387.622192\n",
      "epoch 11, loss: 4624.299805\n",
      "epoch 12, loss: 3747.817871\n",
      "epoch 13, loss: 3906.764648\n",
      "epoch 14, loss: 6302.432617\n",
      "epoch 15, loss: 3515.139404\n",
      "epoch 16, loss: 8976.093750\n",
      "epoch 17, loss: 3615.606201\n",
      "epoch 18, loss: 999.907471\n",
      "epoch 19, loss: 1323.540894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 2700.04   ]\n",
       " [  893.33295]\n",
       " [-2629.5718 ]\n",
       " ...\n",
       " [ 2640.728  ]\n",
       " [ 1266.9835 ]\n",
       " [ 2122.7158 ]]\n",
       "<NDArray 16000x1 @cpu(0)>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unbiased\n",
    "ub_train_data, ub_train_labels = makeTrainData(class_1_train, class_neg1_train, 12000, .5)\n",
    "\n",
    "#biased\n",
    "biased_train_data, biased_train_labels = makeTrainData(class_1_train, class_neg1_train, 12000, .1)\n",
    "\n",
    "#for binary classifier on test vs train\n",
    "train_data = nd.concat(ub_train_data, test_data, dim = 0)\n",
    "ub1_train_data = train_data.astype('float32')\n",
    "train_labels = nd.concat(nd.ones(len(ub_train_data)), nd.ones(len(test_data))*-1, dim = 0)\n",
    "ub1_train_labels = train_labels.astype('float32')\n",
    "                         \n",
    "train_data = nd.concat(biased_train_data, test_data, dim = 0)\n",
    "b1_train_data = train_data.astype('float32')\n",
    "train_labels = nd.concat(nd.ones(len(biased_train_data)), nd.ones(len(test_data))*-1, dim = 0)\n",
    "b1_train_labels = train_labels.astype('float32')\n",
    "\n",
    "def train_for_weights(Xtrain, ytrain):\n",
    "    batch_size = 16\n",
    "    num_epochs = 20\n",
    "    \n",
    "    print(ytrain)\n",
    "    train_dataset = gdata.ArrayDataset(Xtrain, ytrain)\n",
    "    train_iter = gdata.DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "\n",
    "    def loss(o, y):\n",
    "        loss = gluon.loss.LogisticLoss()\n",
    "        return loss(o, y)\n",
    "\n",
    "    def net():\n",
    "        net = nn.Sequential()\n",
    "        net.add(nn.Dense(1))\n",
    "        net.initialize(init.Normal(sigma=1))\n",
    "        return net\n",
    "\n",
    "    net = net()\n",
    "    trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.01})\n",
    "    for epoch in range(num_epochs):\n",
    "        for X, y in train_iter:\n",
    "            with autograd.record():\n",
    "                l = loss(net(X), y)\n",
    "            l.backward()\n",
    "            trainer.step(batch_size)\n",
    "        l = loss(net(Xtrain), ytrain)\n",
    "        print('epoch %d, loss: %f' % (epoch, l.mean().asnumpy()))\n",
    "    \n",
    "    return net(Xtrain)\n",
    "                         \n",
    "train_for_weights(ub1_train_data, ub1_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ 1.  1.  1. ... -1. -1. -1.]\n",
      "<NDArray 16000 @cpu(0)>\n",
      "epoch 0, loss: 3744.067871\n",
      "epoch 1, loss: 3223.222900\n",
      "epoch 2, loss: 1034.274170\n",
      "epoch 3, loss: 2775.221191\n",
      "epoch 4, loss: 2080.456055\n",
      "epoch 5, loss: 1108.661987\n",
      "epoch 6, loss: 2918.534668\n",
      "epoch 7, loss: 3443.694580\n",
      "epoch 8, loss: 2521.323730\n",
      "epoch 9, loss: 1301.726440\n",
      "epoch 10, loss: 1714.048584\n",
      "epoch 11, loss: 1421.738770\n",
      "epoch 12, loss: 1201.814209\n",
      "epoch 13, loss: 4083.874268\n",
      "epoch 14, loss: 754.815308\n",
      "epoch 15, loss: 1624.795044\n",
      "epoch 16, loss: 2816.681885\n",
      "epoch 17, loss: 2397.985107\n",
      "epoch 18, loss: 1037.171265\n",
      "epoch 19, loss: 1069.557983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "[[-161.50974]\n",
       " [2786.992  ]\n",
       " [  14.17483]\n",
       " ...\n",
       " [5453.8535 ]\n",
       " [ 379.6688 ]\n",
       " [7792.6426 ]]\n",
       "<NDArray 16000x1 @cpu(0)>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_for_weights(b1_train_data,b1_train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3. Was unable to obtain proper weights for either class - both the weights went to inf since the function was taking the exp of a large number and the binary classifier did not converge when training to differentiate between train and test sets. However, we would expect the weights to be different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if part 3 had worked, we would weight each training step by exp(net(xi)) in the training loop, however \n",
    "#the weights from the above part are unreliable since the binary classifier did not work very well and we \n",
    "#are left with meaningless weights\n",
    "\n",
    "\n",
    "def train_with_shift(Xtrain, ytrain, Xtest, ytest):\n",
    "    batch_size = 64\n",
    "    num_epochs = 20\n",
    "    \n",
    "    train_dataset = gdata.ArrayDataset(Xtrain, ytrain)\n",
    "    train_iter = gdata.DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "\n",
    "    def loss(o, y):\n",
    "        loss = gluon.loss.LogisticLoss()\n",
    "        return loss(o, y)\n",
    "\n",
    "    def net():\n",
    "        net = nn.Sequential()\n",
    "        net.add(nn.Dense(1))\n",
    "        net.initialize(init.Normal(sigma=1))\n",
    "        return net\n",
    "\n",
    "    net = net()\n",
    "    trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.1})\n",
    "    for epoch in range(num_epochs):\n",
    "        for X, y in train_iter:\n",
    "            with autograd.record():\n",
    "                l = nd.exp(min(net(X), 1)) * loss(net(X), y)\n",
    "            l.backward()\n",
    "            trainer.step(batch_size)\n",
    "        l = loss(net(Xtrain), ytrain)\n",
    "        print('epoch %d, loss: %f' % (epoch, l.mean().asnumpy()))\n",
    "    \n",
    "    return net(Xtest)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
