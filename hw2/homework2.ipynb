{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2 - Berkeley STAT 157\n",
    "\n",
    "Handout 1/29/2019, due 2/5/2019 by 4pm in Git by committing to your repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T22:48:56.163323Z",
     "start_time": "2019-01-29T22:48:53.680455Z"
    }
   },
   "outputs": [],
   "source": [
    "from mxnet import nd, autograd, gluon\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T19:41:18.204791Z",
     "start_time": "2019-01-29T19:41:18.201091Z"
    }
   },
   "source": [
    "# 1. Multinomial Sampling\n",
    "\n",
    "Implement a sampler from a discrete distribution from scratch, mimicking the function `mxnet.ndarray.random.multinomial`. Its arguments should be a vector of probabilities $p$. You can assume that the probabilities are normalized, i.e. tha they sum up to $1$. Make the call signature as follows:\n",
    "\n",
    "```\n",
    "samples = sampler(probs, shape) \n",
    "\n",
    "probs   : An ndarray vector of size n of nonnegative numbers summing up to 1\n",
    "shape   : A list of dimensions for the output\n",
    "samples : Samples from probs with shape matching shape\n",
    "```\n",
    "\n",
    "Hints:\n",
    "\n",
    "1. Use `mxnet.ndarray.random.uniform` to get a sample from $U[0,1]$.\n",
    "1. You can simplify things for `probs` by computing the cumulative sum over `probs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T22:48:56.185124Z",
     "start_time": "2019-01-29T22:48:56.165645Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[2. 2. 2.]\n",
       " [2. 2. 2.]]\n",
       "<NDArray 2x3 @cpu(0)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sampler(probs, shape):\n",
    "    cumsum = 0\n",
    "    arr = [0]\n",
    "    for i in range(len(probs)):\n",
    "        cumsum = cumsum + probs[i]\n",
    "        arr = np.append(arr, cumsum)\n",
    "    sample = nd.random.uniform()\n",
    "    def search(probs, samples):\n",
    "        low = 0\n",
    "        high = len(probs)-1\n",
    "        mid = (low + high) // 2\n",
    "        while not (probs[mid] <= sample and probs[mid + 1] > sample):\n",
    "            if probs[mid] < sample:\n",
    "                low = mid\n",
    "            elif probs[mid] > sample:\n",
    "                high = mid\n",
    "            elif probs[mid] == sample:\n",
    "                return mid\n",
    "            mid = (low + high) // 2\n",
    "        return mid\n",
    "    ret = nd.zeros(shape)\n",
    "    for i in range(shape[0]):\n",
    "        for j in range(shape[1]):\n",
    "            sample = nd.random.uniform()\n",
    "            ret[i, j] = search(arr, sample)\n",
    "    return ret\n",
    "# a simple test\n",
    "sampler(nd.array([0.2, 0.3, 0.5]), (2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Central Limit Theorem\n",
    "\n",
    "Let's explore the Central Limit Theorem when applied to text processing. \n",
    "\n",
    "* Download [https://www.gutenberg.org/ebooks/84](https://www.gutenberg.org/files/84/84-0.txt) from Project Gutenberg \n",
    "* Remove punctuation, uppercase / lowercase, and split the text up into individual tokens (words).\n",
    "* For the words `a`, `and`, `the`, `i`, `is` compute their respective counts as the book progresses, i.e. \n",
    "    $$n_\\mathrm{the}[i] = \\sum_{j = 1}^i \\{w_j = \\mathrm{the}\\}$$\n",
    "* Plot the proportions $n_\\mathrm{word}[i] / i$ over the document in one plot.\n",
    "* Find an envelope of the shape $O(1/\\sqrt{i})$ for each of these five words.\n",
    "* Why can we **not** apply the Central Limit Theorem directly? \n",
    "* How would we have to change the text for it to apply? \n",
    "* Why does it still work quite well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T22:48:56.200892Z",
     "start_time": "2019-01-29T22:48:56.188145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['project' 'gutenbergs' 'frankenstein' 'by' 'mary' 'wollstonecraft'\n",
      " 'godwin' 'shelley' 'this' 'ebook' 'is' 'for' 'the' 'use' 'of' 'anyone'\n",
      " 'anywhere' 'at' 'no' 'cost' 'and' 'with' 'almost' 'no' 'restrictions'\n",
      " 'whatsoever' 'you' 'may' 'copy' 'it' 'give' 'it' 'away' 'or' 'reuse' 'it'\n",
      " 'under' 'the' 'terms' 'of' 'the' 'project' 'gutenberg' 'license'\n",
      " 'included' 'with' 'this' 'ebook' 'or' 'online' 'at' 'wwwgutenbergnet'\n",
      " 'title' 'frankenstein' 'or' 'the' 'modern' 'prometheus' 'author' 'mary'\n",
      " 'wollstonecraft' 'godwin' 'shelley' 'release' 'date' 'june' 'ebook'\n",
      " 'last' 'updated' 'january' 'language' 'english' 'character' 'set'\n",
      " 'encoding' 'utf' 'start' 'of' 'this' 'project' 'gutenberg' 'ebook'\n",
      " 'frankenstein' 'produced' 'by' 'judith' 'boss' 'christy' 'phillips'\n",
      " 'lynn' 'hanninen' 'and' 'david' 'meltzer' 'html' 'version' 'by' 'al'\n",
      " 'haines' 'further']\n"
     ]
    }
   ],
   "source": [
    "filename = gluon.utils.download('https://www.gutenberg.org/files/84/84-0.txt')\n",
    "\n",
    "book = []\n",
    "def clean(word):\n",
    "    cleaned_word = \"\"\n",
    "    for char in word:\n",
    "        if char.isalpha():\n",
    "            cleaned_word = cleaned_word + str(char)\n",
    "    return cleaned_word.lower()\n",
    "\n",
    "with open(filename) as f:\n",
    "    for line in f:\n",
    "        for word in line.split():\n",
    "            cleaned_word = clean(word)\n",
    "            if len(cleaned_word) > 0:\n",
    "                book = np.append(book, cleaned_word)\n",
    "            \n",
    "print(book[0:100])    \n",
    "## Add your codes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 5 artists>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = dict({\"a\": 0, \"and\": 0, \"the\": 0, \"i\": 0, \"is\": 0})\n",
    "for w in book:\n",
    "    if w in counts:\n",
    "        counts[w] = counts[w] + 1\n",
    "for w in counts:\n",
    "    counts[w] = counts[w] / len(book)\n",
    "names = list(counts.keys())\n",
    "values = list(counts.values())\n",
    "\n",
    "plt.bar(names, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1442, 'and': 3040, 'the': 4364, 'i': 2842, 'is': 333}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Denominator-layout notation\n",
    "\n",
    "We used the numerator-layout notation for matrix calculus in class, now let's examine the denominator-layout notation.\n",
    "\n",
    "Given $x, y\\in\\mathbb R$, $\\mathbf x\\in\\mathbb R^n$ and $\\mathbf y \\in \\mathbb R^m$, we have\n",
    "\n",
    "$$\n",
    "\\frac{\\partial y}{\\partial \\mathbf{x}}=\\begin{bmatrix}\n",
    "\\frac{\\partial y}{\\partial x_1}\\\\\n",
    "\\frac{\\partial y}{\\partial x_2}\\\\\n",
    "\\vdots\\\\\n",
    "\\frac{\\partial y}{\\partial x_n}\n",
    "\\end{bmatrix},\\quad \n",
    "\\frac{\\partial \\mathbf y}{\\partial {x}}=\\begin{bmatrix}\n",
    "\\frac{\\partial y_1}{\\partial x}, \n",
    "\\frac{\\partial y_2}{\\partial x}, \n",
    "\\ldots,\n",
    "\\frac{\\partial y_m}{\\partial x}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathbf y}{\\partial \\mathbf{x}}\n",
    "=\\begin{bmatrix}\n",
    "\\frac{\\partial \\mathbf y}{\\partial {x_1}}\\\\\n",
    "\\frac{\\partial \\mathbf y}{\\partial {x_2}}\\\\\n",
    "\\vdots\\\\\n",
    "\\frac{\\partial \\mathbf y}{\\partial {x_3}}\\\\\n",
    "\\end{bmatrix}\n",
    "=\\begin{bmatrix}\n",
    "\\frac{\\partial y_1}{\\partial x_1}, \n",
    "\\frac{\\partial y_2}{\\partial x_1},\n",
    "\\ldots,\n",
    "\\frac{\\partial y_m}{\\partial x_1}\n",
    "\\\\ \n",
    "\\frac{\\partial y_1}{\\partial x_2},\n",
    "\\frac{\\partial y_2}{\\partial x_2},\n",
    "\\ldots,\n",
    "\\frac{\\partial y_m}{\\partial x_2}\\\\ \n",
    "\\vdots\\\\\n",
    "\\frac{\\partial y_1}{\\partial x_n},\n",
    "\\frac{\\partial y_2}{\\partial x_n},\n",
    "\\ldots,\n",
    "\\frac{\\partial y_m}{\\partial x_n}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Questions: \n",
    "\n",
    "1. Assume $\\mathbf  y = f(\\mathbf u)$ and $\\mathbf u = g(\\mathbf x)$, write down the chain rule for $\\frac {\\partial\\mathbf  y}{\\partial\\mathbf x}$\n",
    "2. Given $\\mathbf X \\in \\mathbb R^{m\\times n},\\ \\mathbf w \\in \\mathbb R^n, \\ \\mathbf y \\in \\mathbb R^m$, assume $z = \\| \\mathbf X \\mathbf w - \\mathbf y\\|^2$, compute $\\frac{\\partial z}{\\partial\\mathbf w}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Numerical Precision\n",
    "\n",
    "Given scalars `x` and `y`, implement the following `log_exp` function such that it returns a numerically stable version of \n",
    "$$-\\log\\left(\\frac{e^x}{e^x+e^y}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T22:48:56.206890Z",
     "start_time": "2019-01-29T22:48:56.202996Z"
    }
   },
   "outputs": [],
   "source": [
    "def log_exp(x, y):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your codes with normal inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T22:48:56.215579Z",
     "start_time": "2019-01-29T22:48:56.209659Z"
    }
   },
   "outputs": [],
   "source": [
    "x, y = nd.array([2]), nd.array([3])\n",
    "z = log_exp(x, y)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now implement a function to compute $\\partial z/\\partial x$ and $\\partial z/\\partial y$ with `autograd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T22:48:56.223303Z",
     "start_time": "2019-01-29T22:48:56.218056Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grad(forward_func, x, y): \n",
    "    ## Add your codes here\n",
    "    print('x.grad =', x.grad)\n",
    "    print('y.grad =', y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your codes, it should print the results nicely. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T22:48:56.267165Z",
     "start_time": "2019-01-29T22:48:56.227035Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad = None\n",
      "y.grad = None\n"
     ]
    }
   ],
   "source": [
    "grad(log_exp, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now let's try some \"hard\" inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T22:48:56.285842Z",
     "start_time": "2019-01-29T22:48:56.274079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad = None\n",
      "y.grad = None\n"
     ]
    }
   ],
   "source": [
    "x, y = nd.array([50]), nd.array([100])\n",
    "grad(log_exp, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does your code return correct results? If not, try to understand the reason. (Hint, evaluate `exp(100)`). Now develop a new function `stable_log_exp` that is identical to `log_exp` in math, but returns a more numerical stable result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T22:48:56.305595Z",
     "start_time": "2019-01-29T22:48:56.293399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad = None\n",
      "y.grad = None\n"
     ]
    }
   ],
   "source": [
    "def stable_log_exp(x, y):\n",
    "    ## Add your codes here\n",
    "    pass\n",
    "\n",
    "grad(stable_log_exp, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
